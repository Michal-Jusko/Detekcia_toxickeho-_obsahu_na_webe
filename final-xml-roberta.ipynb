{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"34bf9e13-3d21-4d20-bc55-12bd15bc8f29","cell_type":"markdown","source":"# 1. Inštalácia knižníc a prostredia","metadata":{}},{"id":"01dacc51","cell_type":"code","source":"# Trainer nepracuje správne v novšej verzii \n#Úplné odstránenie nekompatibilných verzií\n!pip uninstall -y transformers huggingface-hub tokenizers sentence-transformers peft\n\n# Vyčistenie cache\n!rm -rf /root/.cache/huggingface\n\n#Inštalácia stabilných verzií\n!pip install transformers==4.40.1 huggingface-hub==0.30.2 tokenizers==0.19.1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f80046c2","cell_type":"code","source":"#  Vyhodnocovacia funkcia – metriky pre binárnu klasifikáciu\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport numpy as np\n\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    labels = p.label_ids\n    return {\n        \"eval_accuracy\": accuracy_score(labels, preds),\n        \"eval_precision\": precision_score(labels, preds),\n        \"eval_recall\": recall_score(labels, preds),\n        \"eval_f1\": f1_score(labels, preds)  # kľúčové pre F1 graf a výber najlepšieho modelu\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"83303fb8-6e7d-4fc6-8a2d-1e0aa7c8328f","cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fc3cd4a9-925a-4deb-8d82-493e8664ef85","cell_type":"markdown","source":"# 2. Načítanie a filtrovanie dát","metadata":{}},{"id":"3e1bf7c0-7bfb-4006-80c8-8b4f1216e519","cell_type":"code","source":"# celý dataset je príliš veľký(3M),na Kaggle to padalo na pamäti\n# len na 20k komentároch ako pri ToxicBERT, aby boli výsledky porovnateľné\n# Načítanie datasetu len SK a EN\nfrom datasets import load_dataset\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Načítame celý dataset a nechame iba sk en\nds = load_dataset(\"FredZhang7/toxi-text-3M\", split=\"train\", verification_mode=\"no_checks\")\ndf = ds.to_pandas()\ndf = df[df[\"lang\"].isin([\"sk\", \"en\"])].reset_index(drop=True)\n\n#pridáme binárny label\ndf[\"label\"] = df[\"is_toxic\"]\n\n# Stratifikovaný výber 20 000 komentárov, rovnaké ako pri ToxicBERT\ndf_sample, _ = train_test_split(df, train_size=20000, stratify=df[\"label\"], random_state=42)\n\n#Rozdelenie na train val test množiny + stratifikovane\ntrain_df, temp_df = train_test_split(df_sample, test_size=0.2, stratify=df_sample[\"label\"], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n\n# Uloženie ako csv\ntrain_df.to_csv(\"train_multilingual.csv\", index=False)\nval_df.to_csv(\"val_multilingual.csv\", index=False)\ntest_df.to_csv(\"test_multilingual.csv\", index=False)\n\nprint(\"Stratifikovanie a rozdelenie hotové:\")\nprint(\"Train:\", train_df.shape, \"| Val:\", val_df.shape, \"| Test:\", test_df.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a73c9331","cell_type":"code","source":"def set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5f1e41aa-75da-4a4c-99f9-3fb28645efe7","cell_type":"markdown","source":"# 3. Tokenizácia a konverzia na Dataset","metadata":{}},{"id":"2fbb79b1","cell_type":"code","source":"checkpoint = \"xlm-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint),\n# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n# skúšal som aj large verziu, ale bola výrazne pomalšia\n\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_ds = Dataset.from_pandas(train_df).map(tokenize, batched=True).remove_columns([\"text\", \"lang\"])\nvalid_ds = Dataset.from_pandas(val_df).map(tokenize, batched=True).remove_columns([\"text\", \"lang\"])\ntest_ds = Dataset.from_pandas(test_df).map(tokenize, batched=True).remove_columns([\"text\", \"lang\"])\n\ntrain_ds = train_ds.rename_column(\"label\", \"labels\")\nvalid_ds = valid_ds.rename_column(\"label\", \"labels\")\ntest_ds = test_ds.rename_column(\"label\", \"labels\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b3d6a937","cell_type":"code","source":"training_losses = []\nvalidation_losses = []\neval_accuracies = []\nepochs_logged = []\n\nclass EpochMetricsTracker(TrainerCallback):\n    def __init__(self):\n        self.last_logged_epoch = -1\n\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs and 'loss' in logs and 'epoch' in logs:\n            epoch = int(logs['epoch'])\n            if epoch != self.last_logged_epoch:\n                training_losses.append(logs['loss'])\n                self.last_logged_epoch = epoch\n\n    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n        if metrics:\n            if 'eval_loss' in metrics:\n                validation_losses.append(metrics['eval_loss'])\n            if 'eval_accuracy' in metrics:\n                eval_accuracies.append(metrics['eval_accuracy'])\n            epochs_logged.append(int(state.epoch))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1089c3be-cea3-497d-a5fe-22298d22ddb0","cell_type":"markdown","source":"# 4. Tréningové argumenty + trénovanie modelu","metadata":{}},{"id":"162252ee","cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5, #  pri 3e-5 sa rýchlo preučil\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    num_train_epochs=7,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_f1\",\n    greater_is_better=True,\n    logging_dir=\"./logs\",\n    logging_strategy=\"epoch\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=valid_ds,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EpochMetricsTracker(), EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"446eb818","cell_type":"code","source":"from datasets import Dataset\ncheckpoint = \"xlm-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\ndef tokenize(example):\n    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_ds = Dataset.from_pandas(train_df).map(tokenize, batched=True)\nval_ds = Dataset.from_pandas(val_df).map(tokenize, batched=True)\ntest_ds = Dataset.from_pandas(test_df).map(tokenize, batched=True)\n\nfor ds in [train_ds, val_ds, test_ds]:\n    ds = ds.rename_column(\"label\", \"labels\")\n    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9c6213ed-0a48-4258-ad85-deb0b22acc6f","cell_type":"markdown","source":"# 5. Vyhodnotenie výsledkov a vizualizácia","metadata":{}},{"id":"7b64cf2d","cell_type":"code","source":"#Vyhodnotenie modelu \nfrom sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef, roc_auc_score, precision_recall_curve, auc, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport os\n\n# Predikcia na testovacej množine\npreds_output = trainer.predict(test_ds)\nlabels = preds_output.label_ids\npreds = np.argmax(preds_output.predictions, axis=1)\nprobs = torch.nn.functional.softmax(torch.tensor(preds_output.predictions), dim=1)[:, 1].numpy()\n\n#  priečinok pre uloženie\nos.makedirs(\"results\", exist_ok=True)\n\n# Klasifikačný report\nreport = classification_report(labels, preds, target_names=[\"Non-toxic\", \"Toxic\"], digits=4)\nwith open(\"results/classification_report.txt\", \"w\") as f:\n    f.write(report)\n\n# Klasifikačný report do scv\nreport_dict = classification_report(labels, preds, target_names=[\"Non-toxic\", \"Toxic\"], digits=4, output_dict=True)\npd.DataFrame(report_dict).transpose().to_csv(\"results/classification_report_full.csv\")\n\n                             \n# MCC\nmcc = matthews_corrcoef(labels, preds)\nprint(\"Matthews Correlation Coefficient (MCC):\", round(mcc, 4))\n\n# Confusion Matrix\ncm = confusion_matrix(labels, preds)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-toxic\", \"Toxic\"], yticklabels=[\"Non-toxic\", \"Toxic\"])\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.tight_layout()\nplt.savefig(\"results/confusion_matrix.png\")\nplt.close()                                   \n\n# ROC\nfpr, tpr, _ = roc_curve(labels, probs)\nroc_auc = roc_auc_score(labels, probs)\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.4f}\", color=\"darkorange\")\nplt.plot([0, 1], [0, 1], \"k--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(\"results/roc_curve.png\")\nplt.close()                             \n\n# Precision-recall \nprecision, recall, _ = precision_recall_curve(labels, probs)\npr_auc = auc(recall, precision)\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.4f}\", color=\"blue\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision-Recall Curve\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\n\n\n\nplt.savefig(\"results/pr_curve.png\")\nplt.close()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"043b7bbd","cell_type":"code","source":"# Tréningové metriky \nepoch_logs = [x for x in trainer.state.log_history if \"epoch\" in x and \"eval_loss\" in x]\ntrain_loss_epoch = [x[\"loss\"] for x in trainer.state.log_history if \"loss\" in x and \"epoch\" in x]\nval_loss_epoch = [x[\"eval_loss\"] for x in epoch_logs]\n\nf1_epoch = [x[\"eval_f1\"] for x in epoch_logs if \"eval_f1\" in x]\nepochs = [x[\"epoch\"] for x in epoch_logs]\n\ndef smooth(values, alpha=0.3):\n    if not values:\n        return []\n    smoothed = []\n    last = values[0]\n    for v in values:\n        smoothed_val = alpha * v + (1 - alpha) * last\n        smoothed.append(smoothed_val)\n        last = smoothed_val\n    return smoothed\n\n\n\nif train_loss_epoch and val_loss_epoch:\n    plt.figure(figsize=(10, 6))\n    plt.plot(epochs, smooth(train_loss_epoch), label=\"Train Loss\", linewidth=2)\n    plt.plot(epochs, smooth(val_loss_epoch), label=\"Validation Loss\", linewidth=2)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training and Validation Loss\")\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(\"results/loss_clean_graph.png\")\n    plt.show()\n\nif f1_epoch:\n    plt.figure(figsize=(10, 6))\n    plt.plot(epochs, smooth(f1_epoch), marker='o', label=\"F1 Score\", linewidth=2)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"F1\")\n    plt.title(\"F1 Score Over Epochs\")\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(\"results/accuracy_graph.png\")\n\n    \n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"14575e69-8feb-47f6-843f-3a88dfe59ccd","cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile(\"final_results_multilingual.zip\", \"w\") as zipf:\n    for file in os.listdir(\"results\"):\n        zipf.write(os.path.join(\"results\", file), arcname=file)\nprint(\"✅ Výstupy boli zozipované.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}