{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11779261,"sourceType":"datasetVersion","datasetId":7395192}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"26942905","cell_type":"markdown","source":"# 1. Inštalácia knižníc a prostredia","metadata":{}},{"id":"f666aaaa","cell_type":"code","source":"# Trainer nepracuje správne v novšej verzii \n#Úplné odstránenie nekompatibilných verzií\n!pip uninstall -y transformers huggingface-hub tokenizers sentence-transformers peft\n\n# Vyčistenie cache\n!rm -rf /root/.cache/huggingface\n\n#Inštalácia stabilných verzií\n!pip install transformers==4.40.1 huggingface-hub==0.30.2 tokenizers==0.19.1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"00397d38-7105-4074-82c6-316dab699a44","cell_type":"markdown","source":"# 2. Načítanie a úprava datasetu","metadata":{}},{"id":"e1e637c4","cell_type":"code","source":"\n!pip install -q datasets pandas scikit-learn numpy tqdm\n\n\n\nfrom datasets import load_dataset\nimport pandas as pd\nfrom tqdm import tqdm\n\n#Načítanie datasetu\nprint(\"Načítavam dataset\")\ndataset = load_dataset(\"civil_comments\")\n\n# Upravené bez severe_toxicity Pôvodne som chcel ponechať aj severe_toxicity, ale bolo tam príliš málo príkladov\n\n\nlabel_columns = [\"toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"sexual_explicit\"]\ndf_train = pd.DataFrame(dataset[\"train\"])[[\"text\"] + label_columns]\ndf_test = pd.DataFrame(dataset[\"test\"])[[\"text\"] + label_columns]\n\n\n# Binarizácia: >= 0.5 išlo na 1\ndf_train[label_columns] = (df_train[label_columns] >= 0.5).astype(int)\ndf_test[label_columns] = (df_test[label_columns] >= 0.5).astype(int)\n\n\n\n# Sampling funkcia s progress barom\ndef balanced_subset(df, label_cols, min_per_label):\n    samples = []\n    for col in tqdm(label_cols, desc=\"⏳ Sampling podľa štítkov\"):\n        n = min(min_per_label, df[col].sum())\n        samples.append(df[df[col] == 1].sample(n=n, random_state=42))\n    combined = pd.concat(samples).drop_duplicates().sample(frac=1, random_state=42)\n    return combined\n\n# Výber zmenšených množín\ntrain_small = balanced_subset(df_train, label_columns, 3000)\ntest_valid_pool = balanced_subset(df_test, label_columns, 500)\nvalid_small = test_valid_pool.sample(frac=0.5, random_state=42)\ntest_small = test_valid_pool.drop(index=valid_small.index)\n\n# previesť všetky labely na float32 lebo int nefunguje\nfor df in [train_small, valid_small, test_small]:\n    df[label_columns] = df[label_columns].astype(\"float32\")\n\n#Uloženie dat do csv        \n\n\ntrain_small.to_csv(\"train_multilabel_small.csv\", index=False)\nvalid_small.to_csv(\"valid_multilabel_small.csv\", index=False)\ntest_small.to_csv(\"test_multilabel_small.csv\", index=False)\n\nprint(f\"Tréningový: {len(train_small)} komentárov\")\nprint(f\"Validačný: {len(valid_small)} komentárov\")\nprint(f\"Testovací: {len(test_small)} komentárov\")\nprint(\"\\nDistribúcia trénovacích dát  :\")\nprint(train_small[label_columns].sum())\nprint(\"\\nDistribúcia validačných dát: \")\nprint(valid_small[label_columns].sum())\nprint(\"\\nDistribúcia testovacích dát: \")\nprint(test_small[label_columns].sum())\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2ae4b921-23dd-4393-9882-1668e7f409ea","cell_type":"markdown","source":"# 3. Import knižníc","metadata":{}},{"id":"093351f9","cell_type":"code","source":"\n\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\nfrom datasets import load_dataset, DatasetDict, Dataset\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n# import evaluate  # pouzite radsej sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport random\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"008be29e-8ea7-43af-8acf-dc60765a7f0b","cell_type":"markdown","source":"# 3. Tokenizácia a príprava dát pre model","metadata":{}},{"id":"88770188","cell_type":"code","source":"\nfrom datasets import Dataset\nimport pandas as pd\nfrom transformers import AutoTokenizer\n\n\n\n                                        \n# Načítanie datasetu\ntrain_df = pd.read_csv(\"/kaggle/input/miltilabel/train_multilabel_small(1).csv\")\nval_df = pd.read_csv(\"/kaggle/input/miltilabel/valid_multilabel_small.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/miltilabel/test_multilabel_small(1).csv\")\n\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)\ntest_ds = Dataset.from_pandas(test_df)\n\n\n# Tokenizácia\ncheckpoint = \"unitary/toxic-bert\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\n\ntrain_ds = train_ds.map(tokenize_function, batched=True)\nval_ds = val_ds.map(tokenize_function, batched=True)\ntest_ds = test_ds.map(tokenize_function, batched=True)\n\n\n#Nastavenie dát pre trainer\nlabel_columns = ['toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit']\ntrain_ds.set_format(type='torch', columns=['input_ids', 'attention_mask'] + label_columns)\nval_ds.set_format(type='torch', columns=['input_ids', 'attention_mask'] + label_columns)\ntest_ds.set_format(type='torch', columns=['input_ids', 'attention_mask'] + label_columns)\n\n\n# Vytvorenie 'labels' z viacerých labelov\ndef add_labels(example):\n    example[\"labels\"] = [example[col] for col in label_columns]\n    return example\n\ntrain_ds = train_ds.map(add_labels)\nval_ds = val_ds.map(add_labels)\ntest_ds = test_ds.map(add_labels)\n\n\n#Nastavenie výstupných stĺpcov\ntrain_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\nval_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\ntest_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"85c9255d-41c3-47d4-9be3-b76dd28c91ed","cell_type":"markdown","source":"# 4. Definovanie modelu a metrík + Tréning modelu","metadata":{}},{"id":"06e11648","cell_type":"code","source":"from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n# import evaluate  # pouzite sklearn\nimport numpy as np\nimport torch\n\n\n\n# Definuje labely\nlabel_columns = [\"toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"sexual_explicit\"]\n\n# Nastavenie checkpointu\ncheckpoint = \"unitary/toxic-bert\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# Konfigurácia pre multilabel klasifikáciu\nconfig = AutoConfig.from_pretrained(checkpoint)\nconfig.num_labels = len(label_columns)\nconfig.problem_type = \"multi_label_classification\"\n\n\n\n# model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    checkpoint,\n    config=config,\n    ignore_mismatched_sizes=True\n).to(device)\n\n# potreben pre metriky pre multilabel\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# Metriky pre multilabel \ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n    preds = (probs >= 0.5).astype(int)\n\n    return {\n        \"accuracy_micro\": accuracy_score(labels, preds),\n        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n        \"f1_micro\": f1_score(labels, preds, average=\"micro\")\n    }\n                                          \n# Skúšal som learning_rate=3e-5 a batch_size=16, ale model sa rýchlo preučiť\n\n# Tréningové argumenty\ntraining_args = TrainingArguments(\n    results_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    num_train_epochs=5,\n    learning_rate=1e-5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_micro\",\n    greater_is_better=True,\n    report_to=\"none\"\n)  \n\n\n\n\n# Tréner\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\n#tréning\ntrain_result = trainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e9b50580-be56-487d-9301-d3d56fd246da","cell_type":"markdown","source":"# 6. Vyhodnotenie modelu","metadata":{}},{"id":"8bd21e50","cell_type":"code","source":"\n#Upravené grafy pre loss a accuracy\n\n\n\nepoch_logs = [x for x in trainer.state.log_history if \"epoch\" in x and \"eval_loss\" in x]\n\ntrain_loss_epoch = [x[\"loss\"] for x in trainer.state.log_history if \"loss\" in x and \"epoch\" in x]\nval_loss_epoch = [x[\"eval_loss\"] for x in epoch_logs]\nf1_micro_epoch = [x[\"eval_f1_micro\"] for x in epoch_logs if \"eval_f1_micro\" in x]\nacc_epoch = [x[\"eval_accuracy\"] for x in epoch_logs if \"eval_accuracy\" in x]\n\n\nepochs = [x[\"epoch\"] for x in epoch_logs]\n\n\n\n# Loss \nplt.figure(figsize=(10, 6))\nplt.plot(epochs, train_loss_epoch, label=\"Train Loss\", color=\"blue\", linewidth=2)\nplt.plot(epochs, val_loss_epoch, label=\"Validation Loss\", color=\"orange\", linewidth=2)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(f\"/kaggle/working/results/loss_clean_graph.png\", dpi=300)\n\nplt.show()\n\n\n# Accuracy \nplt.figure(figsize=(10, 6))\nplt.plot(epochs, acc_epoch, label=\"Validation Accuracy\", marker='s', color=\"green\", linewidth=2)\nplt.plot(epochs, val_loss_epoch, label=\"Validation Loss\", color=\"orange\", linewidth=2)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model Accuracy Over Epochs\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.savefig(f\"/kaggle/working/results/accuracy_graph.png\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a4f1fb5e","cell_type":"code","source":"\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score, matthews_corrcoef, auc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nimport numpy as np\nimport os\n\n              \n# nastaviť výstupný priečinok\nresults_dir = \"./results\"\nos.makedirs(results_dir, exist_ok=True)\n\n#Predikcie na testovacej množine\npreds_output = trainer.predict(test_ds)\nlogits = torch.tensor(preds_output.predictions)\nprobs = torch.sigmoid(logits).numpy()               \nlabels = preds_output.label_ids\nfinal_preds = (probs >= 0.5).astype(int)\n\n\n# Zoznam štítkov musí byť definovaný skôr v kóde\n# label_columns = [\"toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"sexual_explicit\"]\n\n\n\n# Classification Report\nreport = classification_report(labels, final_preds, target_names=label_columns, digits=4, output_dict=True)\npd.DataFrame(report).transpose().to_csv(f\"{results_dir}/classification_report_multilabel.csv\")\nprint(pd.DataFrame(report).transpose())\n\n#MCC \nmcc_scores = [matthews_corrcoef(labels[:, i], final_preds[:, i]) for i in range(len(label_columns))]\nfor label, mcc in zip(label_columns, mcc_scores):\n    print(f\"MCC for {label}: {mcc:.4f}\")\n\n#Confusion matrix pre každý label samostatne\nfor i, label in enumerate(label_columns):\n    cm = confusion_matrix(labels[:, i], final_preds[:, i])\n    plt.figure(figsize=(4, 3))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n                xticklabels=[\"Non-toxic\", \"Toxic\"],\n                yticklabels=[\"Non-toxic\", \"Toxic\"])\n    plt.title(f\"Confusion Matrix – {label}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.tight_layout()\n    plt.savefig(f\"{results_dir}/confusion_matrix_{label}.png\", dpi=300)\n    plt.close()\n\n#  ROC a PR \nfor i, label in enumerate(label_columns):\n    fpr, tpr, _ = roc_curve(labels[:, i], probs[:, i])\n    precision, recall, _ = precision_recall_curve(labels[:, i], probs[:, i])\n    roc_auc = roc_auc_score(labels[:, i], probs[:, i])\n    pr_auc = auc(recall, precision)\n\n    # ROC \n    plt.figure(figsize=(6, 5))\n    plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.4f}\", color=\"darkorange\")\n    plt.plot([0, 1], [0, 1], \"k--\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(f\"ROC Curve – {label}\")\n    plt.legend()\n    plt.grid(True)           \n    \n    plt.tight_layout()\n    plt.savefig(f\"{results_dir}/roc_curve_{label}.png\", dpi=300)\n    plt.close()\n\n    # PR \n    plt.figure(figsize=(6, 5))\n    plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.4f}\", color=\"blue\")\n    plt.xlabel(\"Recall\")             \n    plt.ylabel(\"Precision\")\n    plt.title(f\"Precision-Recall Curve – {label}\")\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f\"{results_dir}/pr_curve_{label}.png\", dpi=300)\n    plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"673c47ed-2640-451f-8461-8af98cd39917","cell_type":"code","source":"import zipfile\nimport os\n\n# Názov výstupného zipka\nzip_filename = \"model_visualizations.zip\"\nresults_dir  = \"./results\"\n\n# Vytvorenie zip archívu\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    for root, _, files in os.walk(results_dir):\n        for file in files:\n            if file.endswith(\".png\"):\n                file_path = os.path.join(root, file)\n                zipf.write(file_path, arcname=os.path.relpath(file_path, results_dir))\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6f278cc5","cell_type":"code","source":"\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n#  mikro, makro a weighted metriky\nf1_micro = f1_score(labels, final_preds, average='micro')\nf1_macro = f1_score(labels, final_preds, average='macro')\nf1_weighted = f1_score(labels, final_preds, average='weighted')\n\nprecision_micro = precision_score(labels, final_preds, average='micro')\nprecision_macro = precision_score(labels, final_preds, average='macro')\nprecision_weighted = precision_score(labels, final_preds, average='weighted')\n\nrecall_micro = recall_score(labels, final_preds, average='micro')\nrecall_macro = recall_score(labels, final_preds, average='macro')\nrecall_weighted = recall_score(labels, final_preds, average='weighted')\n\nprint(f\"F1 micro: {f1_micro:.4f}\")\nprint(f\"F1 macro: {f1_macro:.4f}\")\nprint(f\"F1 weighted: {f1_weighted:.4f}\")\nprint(f\"Precision micro: {precision_micro:.4f}\")\nprint(f\"Precision macro: {precision_macro:.4f}\")\nprint(f\"Precision weighted: {precision_weighted:.4f}\")\nprint(f\"Recall micro: {recall_micro:.4f}\")\nprint(f\"Recall macro: {recall_macro:.4f}\")\nprint(f\"Recall weighted: {recall_weighted:.4f}\")\n\n# Uloženie do CSV pre bakalárku\nimport pandas as pd\nmetrics_summary = pd.DataFrame({\n    \"F1\": [f1_micro, f1_macro, f1_weighted],\n    \"Precision\": [precision_micro, precision_macro, precision_weighted],\n    \"Recall\": [recall_micro, recall_macro, recall_weighted]\n}, index=[\"micro\", \"macro\", \"weighted\"])\n\nmetrics_summary.to_csv(f\"{results_dir}/micro_macro_metrics.csv\", float_format=\"%.4f\")\nmetrics_summary\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9faf10ee-ed69-4c07-9c67-5dbb4e98234c","cell_type":"code","source":"# Získanie predikcií na test\npreds_output = trainer.predict(test_ds)\nlabels = preds_output.label_ids\nprobs = torch.nn.functional.softmax(torch.tensor(preds_output.predictions), dim=1).numpy()\npreds = (probs > 0.5).astype(int)\n\n# Definícia názvov labelov\nlabel_cols = [\"toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"sexual_explicit\"]\n\n#  MCC, ROC AUC a PR AUC pre každú triedu samostatne\nfrom sklearn.metrics import matthews_corrcoef, roc_auc_score, precision_recall_curve, auc\n\nprint(\"Metriky pre každú triedu:\")\nprint(\"-\" * 60)\nfor i, label in enumerate(label_cols):\n    mcc = matthews_corrcoef(labels[:, i], preds[:, i])\n    try:\n        roc_auc = roc_auc_score(labels[:, i], probs[:, i])\n    except:\n        roc_auc = float('nan')\n    precision, recall, _ = precision_recall_curve(labels[:, i], probs[:, i])\n    pr_auc = auc(recall, precision)\n    print(f\"{label:20} | MCC: {mcc:.4f} | ROC AUC: {roc_auc:.4f} | PR AUC: {pr_auc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"75bc6003","cell_type":"code","source":"# uloženie klasifikačného reportu \nfrom sklearn.metrics import classification_report\n\nreport_txt = classification_report(labels, preds, target_names=label_cols, digits=4)\nwith open(\"results/classification_report.txt\", \"w\") as f:\n    f.write(report_txt)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"cb801807","cell_type":"code","source":"\nfrom sklearn.metrics import matthews_corrcoef, roc_auc_score, precision_recall_curve, auc\n\nfor i, label in enumerate(label_cols):\n    mcc = matthews_corrcoef(labels[:, i], preds[:, i])\n    try:\n        roc_auc = roc_auc_score(labels[:, i], probs[:, i])\n    except:\n        roc_auc = float('nan')\n    precision, recall, _ = precision_recall_curve(labels[:, i], probs[:, i])\n    pr_auc = auc(recall, precision)\n    print(f\"{label:20} | MCC: {mcc:.4f} | ROC AUC: {roc_auc:.4f} | PR AUC: {pr_auc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1b78a117-7d8f-4b24-8301-0ef5736fb819","cell_type":"code","source":"# Odstráni súbor\n#!rm /kaggle/working/final_results_multilabel.zip\n\n# Odstráni celý priečinok rekurzívne\n#!rm -r /kaggle/working/final_results_multilabel.zip\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"48ec01de","cell_type":"code","source":"# F1 Micro\nimport matplotlib.pyplot as plt\n\nepoch_logs = [x for x in trainer.state.log_history if \"epoch\" in x and \"eval_f1_micro\" in x]\nf1_micro_epoch = [x[\"eval_f1_micro\"] for x in epoch_logs]\nepochs = [x[\"epoch\"] for x in epoch_logs]\n\ndef smooth(values, alpha=0.3):\n    smoothed = []\n    last = values[0]\n    for v in values:\n        smoothed_val = alpha * v + (1 - alpha) * last\n        smoothed.append(smoothed_val)\n        last = smoothed_val\n    return smoothed\n\nplt.figure(figsize=(10, 6))\nplt.plot(epochs, smooth(f1_micro_epoch), marker='o', linewidth=2, label=\"F1 Micro\")\nplt.xlabel(\"Epochs\", fontsize=14)\nplt.ylabel(\"F1 Micro\", fontsize=14)\nplt.title(\"Model Performance Over Epochs\", fontsize=16)\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.savefig(\"results/accuracy_graph.png\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"61bf2bd0","cell_type":"code","source":"# Zlúčené ROC a PR kriviek do jedneho grafu\nfrom sklearn.metrics import roc_curve, precision_recall_curve, auc\n\n# ROC\nplt.figure(figsize=(8, 6))\nfor i, label in enumerate(label_cols):\n    fpr, tpr, _ = roc_curve(labels[:, i], probs[:, i])\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label=f\"{label} (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], 'k--')\nplt.title(\"ROC Curve (All Labels)\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(\"results/roc_curve.png\", dpi=300)\nplt.show()\n\n# PR\nplt.figure(figsize=(8, 6))\nfor i, label in enumerate(label_cols):\n    precision, recall, _ = precision_recall_curve(labels[:, i], probs[:, i])\n    pr_auc = auc(recall, precision)\n    plt.plot(recall, precision, label=f\"{label} (AUC = {pr_auc:.2f})\")\nplt.title(\"Precision-Recall Curve (All Labels)\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(\"results/pr_curve.png\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"813212eb-7077-4d41-8bcf-703c08859a77","cell_type":"code","source":"import zipfile\nimport os\n\n# Výstupne zipko\nzip_filename = \"final_results_toxicbert_multilabel.zip\"\nresults_dir= \"./results\"\n\n\n\ninclude_extensions = [\".png\", \".csv\", \".txt\"]\ninclude_files = []\n\n# vyberie do zip len subory ktore treba su v include_extensions\nfor root, dirs, files in os.walk(results_dir):\n    for file in files:\n        if any(file.endswith(ext) for ext in include_extensions):\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, results_dir)\n            include_files.append((file_path, arcname))\n\n#Vytvorenie ZIP archívu\nwith zipfile.ZipFile(zip_filename, \"w\") as zipf:\n    for file_path, arcname in include_files:\n        zipf.write(file_path, arcname)\n\n\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}